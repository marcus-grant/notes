{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http.md',\n",
       " 'csv.md',\n",
       " 'pcde-module6-content.md',\n",
       " 'document-database.md',\n",
       " 'markdown.md',\n",
       " 'find.md',\n",
       " 'mapbox.md',\n",
       " 'intro-python.md']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of all markdown filenames\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Get path of current notebook\n",
    "CURRENT_PATH = os.getcwd()\n",
    "# Get parent dir of current notebook\n",
    "NOTES_PATH = os.path.dirname(CURRENT_PATH)\n",
    "# Get list of all markdown filenames without path\n",
    "def get_all_note_files(notes_path=NOTES_PATH):\n",
    "    return [f for f in os.listdir(notes_path) if f.endswith('.md')]\n",
    "\n",
    "note_files = get_all_note_files()\n",
    "note_files[:8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF shape: (161, 4)\n",
      "DF column dtypes: filename            object\n",
      "size                 int64\n",
      "ctime       datetime64[ns]\n",
      "mtime       datetime64[ns]\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>size</th>\n",
       "      <th>ctime</th>\n",
       "      <th>mtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>mime-type.md</td>\n",
       "      <td>3219</td>\n",
       "      <td>2023-05-05 17:20:38.886245120</td>\n",
       "      <td>2023-05-05 13:25:31.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>jinja.md</td>\n",
       "      <td>2031</td>\n",
       "      <td>2023-03-13 20:21:02.531521280</td>\n",
       "      <td>2023-03-13 09:51:26.012999936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>nextjs.md</td>\n",
       "      <td>195</td>\n",
       "      <td>2023-03-27 11:24:49.953961728</td>\n",
       "      <td>2023-03-27 11:16:20.836998912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>sql-eda.md</td>\n",
       "      <td>6480</td>\n",
       "      <td>2023-03-27 11:24:49.957152512</td>\n",
       "      <td>2023-03-27 11:10:18.694999040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http.md</td>\n",
       "      <td>3470</td>\n",
       "      <td>2023-03-07 16:00:51.093276672</td>\n",
       "      <td>2023-03-07 11:20:10.497998848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>redis.md</td>\n",
       "      <td>1598</td>\n",
       "      <td>2023-03-23 14:26:55.477783296</td>\n",
       "      <td>2023-03-23 14:25:23.101999104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>pcde-module5-content.md</td>\n",
       "      <td>56869</td>\n",
       "      <td>2023-01-27 16:11:25.871063552</td>\n",
       "      <td>2023-01-25 09:17:25.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>numpy.md</td>\n",
       "      <td>16187</td>\n",
       "      <td>2023-02-17 10:18:18.051048448</td>\n",
       "      <td>2023-02-16 16:27:29.207000064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename   size                         ctime  \\\n",
       "45              mime-type.md   3219 2023-05-05 17:20:38.886245120   \n",
       "131                 jinja.md   2031 2023-03-13 20:21:02.531521280   \n",
       "40                 nextjs.md    195 2023-03-27 11:24:49.953961728   \n",
       "116               sql-eda.md   6480 2023-03-27 11:24:49.957152512   \n",
       "0                    http.md   3470 2023-03-07 16:00:51.093276672   \n",
       "25                  redis.md   1598 2023-03-23 14:26:55.477783296   \n",
       "144  pcde-module5-content.md  56869 2023-01-27 16:11:25.871063552   \n",
       "110                 numpy.md  16187 2023-02-17 10:18:18.051048448   \n",
       "\n",
       "                            mtime  \n",
       "45  2023-05-05 13:25:31.000000000  \n",
       "131 2023-03-13 09:51:26.012999936  \n",
       "40  2023-03-27 11:16:20.836998912  \n",
       "116 2023-03-27 11:10:18.694999040  \n",
       "0   2023-03-07 11:20:10.497998848  \n",
       "25  2023-03-23 14:25:23.101999104  \n",
       "144 2023-01-25 09:17:25.000000000  \n",
       "110 2023-02-16 16:27:29.207000064  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create note files metadata dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create dataframe with note files metadata\n",
    "def construct_notes_meta_df(path=NOTES_PATH):\n",
    "    note_files = get_all_note_files(path)\n",
    "    sizes = [os.path.getsize(f'{path}/{f}') for f in note_files]\n",
    "    ctimes = [os.path.getctime(f'{path}/{f}') for f in note_files]\n",
    "    mtimes = [os.path.getmtime(f'{path}/{f}') for f in note_files]\n",
    "    df = pd.DataFrame({\n",
    "        'filename': note_files,\n",
    "        'size': sizes,\n",
    "        'ctime': ctimes,\n",
    "        'mtime': mtimes,\n",
    "    })\n",
    "    # Convert ctime and mtime columns to datetime\n",
    "    df['ctime'] = pd.to_datetime(df['ctime'], unit='s')\n",
    "    df['mtime'] = pd.to_datetime(df['mtime'], unit='s')\n",
    "    return df\n",
    "\n",
    "# Create a df summarizing function\n",
    "def summarize_df(df):\n",
    "    print(f'DF shape: {df.shape}')\n",
    "    print(f'DF column dtypes: {df.dtypes}')\n",
    "    # Return random subset of rows\n",
    "    return df.sample(8)\n",
    "\n",
    "notes_df = construct_notes_meta_df()\n",
    "summarize_df(notes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size mean: 6.3KB\n",
      "Size median: 3.3KB\n",
      "Size std: 8.9KB\n",
      "Size min: 0B\n",
      "Size 1st quartile: 1.4KB\n",
      "Size 3rd quartile: 7.3KB\n",
      "Size max: 55.5KB\n"
     ]
    }
   ],
   "source": [
    "# Helper functions\n",
    "def human_readable_size(size):\n",
    "    if size < 1024:\n",
    "        return f'{size}B'\n",
    "    elif size < 1024 ** 2:\n",
    "        return f'{size / 1024:.1f}KB'\n",
    "    elif size < 1024 ** 3:\n",
    "        return f'{size / (1024 ** 2):.1f}MB'\n",
    "    else:\n",
    "        return f'{size / (1024 ** 3):.1f}GB'\n",
    "# Get stats on note sizes\n",
    "def summarize_notes_df_sizes_stats(df):\n",
    "    size_mean = df['size'].mean()\n",
    "    size_median = df['size'].median()\n",
    "    size_std = df['size'].std()\n",
    "    size_min = df['size'].min()\n",
    "    size_max = df['size'].max()\n",
    "    print(f'Size mean: {human_readable_size(size_mean)}')\n",
    "    print(f'Size median: {human_readable_size(size_median)}')\n",
    "    print(f'Size std: {human_readable_size(size_std)}')\n",
    "    print(f'Size min: {human_readable_size(size_min)}')\n",
    "    print(f'Size 1st quartile: {human_readable_size(df[\"size\"].quantile(0.25))}')\n",
    "    print(f'Size 3rd quartile: {human_readable_size(df[\"size\"].quantile(0.75))}')\n",
    "    print(f'Size max: {human_readable_size(size_max)}')\n",
    "\n",
    "summarize_notes_df_sizes_stats(notes_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot note sizes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot note sizes assuming a log-normal distribution\n",
    "def plot_notes_df_sizes(df):\n",
    "    # Use a histplot\n",
    "    sns.histplot(data=df['size'], x='size', bins=20, log_scale=True)\n",
    "    plt.xlabel('log(size)')\n",
    "    plt.ylabel('density')\n",
    "    plt.title('Note sizes distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing i\n",
      "Removing me\n",
      "Removing my\n",
      "Removing mine\n",
      "Removing myself\n",
      "Removing we\n",
      "Removing us\n",
      "Removing our\n",
      "Removing ours\n",
      "Removing ourselves\n",
      "Removing you\n",
      "Removing your\n",
      "Removing yours\n",
      "Removing yourself\n",
      "Removing yourselves\n",
      "Removing he\n",
      "Removing him\n",
      "Removing his\n",
      "Removing himself\n",
      "Removing she\n",
      "Removing her\n",
      "Removing hers\n",
      "Removing herself\n",
      "Removing it\n",
      "Removing its\n",
      "Removing itself\n",
      "Removing they\n",
      "Removing them\n",
      "Removing their\n",
      "Removing theirs\n",
      "Removing themselves\n",
      "Removing aboard\n",
      "Removing about\n",
      "Removing above\n",
      "Removing across\n",
      "Removing after\n",
      "Removing against\n",
      "Removing along\n",
      "Removing amid\n",
      "Removing among\n",
      "Removing anti\n",
      "Removing around\n",
      "Removing as\n",
      "Removing at\n",
      "Removing before\n",
      "Removing behind\n",
      "Removing below\n",
      "Removing beneath\n",
      "Removing beside\n",
      "Removing besides\n",
      "Removing between\n",
      "Removing beyond\n",
      "Removing but\n",
      "Removing by\n",
      "Removing concerning\n",
      "Removing considering\n",
      "Removing despite\n",
      "Removing down\n",
      "Removing during\n",
      "Removing except\n",
      "Removing excepting\n",
      "Removing excluding\n",
      "Removing following\n",
      "Removing for\n",
      "Removing from\n",
      "Removing in\n",
      "Removing inside\n",
      "Removing into\n",
      "Removing like\n",
      "Removing minus\n",
      "Removing near\n",
      "Removing of\n",
      "Removing off\n",
      "Removing on\n",
      "Removing onto\n",
      "Removing opposite\n",
      "Removing outside\n",
      "Removing over\n",
      "Removing past\n",
      "Removing per\n",
      "Removing plus\n",
      "Removing regarding\n",
      "Removing round\n",
      "Removing save\n",
      "Removing since\n",
      "Removing than\n",
      "Removing through\n",
      "Removing to\n",
      "Removing toward\n",
      "Removing towards\n",
      "Removing under\n",
      "Removing underneath\n",
      "Removing unlike\n",
      "Removing until\n",
      "Removing up\n",
      "Removing upon\n",
      "Removing versus\n",
      "Removing via\n",
      "Removing with\n",
      "Removing within\n",
      "Removing without\n",
      "Removing a\n",
      "Removing b\n",
      "Removing c\n",
      "Removing d\n",
      "Removing e\n",
      "Removing f\n",
      "Removing g\n",
      "Removing h\n",
      "Removing i\n",
      "Removing j\n",
      "Removing k\n",
      "Removing l\n",
      "Removing m\n",
      "Removing n\n",
      "Removing o\n",
      "Removing p\n",
      "Removing q\n",
      "Removing r\n",
      "Removing s\n",
      "Removing t\n",
      "Removing u\n",
      "Removing v\n",
      "Removing w\n",
      "Removing x\n",
      "Removing y\n",
      "Removing z\n",
      " T S Q L SQL T SQL   T  E   S E  P SID PK  FN  C  LN  E  R  C CID FK 1  C E  P CID PK  N  S   R  C T  SQL  T  T  T  F  T SQL  I   T  T   T  T   D  C   U  C T    T  N  A  A     A   U   T  T  W   T  S    I N  B      N  S   W T  U  T  T  T  T  T  A  T  T   IS  T   T  I   A    H  N  Y  T  T  I 1  W  T   H  H MYSQL   T DB  MSQL T        CHAR  F     VARCHAR  V    BINARY  E CHAR    BIT  B   BOOLBOOLEAN  I  0     INTINTEGER  I     FLOAT  F     DATE  A  YYYYMMDD   DATETIME  A  YYYYMMDD    TIME  A    NOTE  F      M MSQL  I   W    W   T  A   T  W    S   S   A  H  I WORM W O R M  H   P   C  J   C W  2   C N   L  T  A   Y  T  T  T  Y  T  B  T   N   Y  F  A   T SQL   C  C   O T S  S  T   B   O    C    S L I    A  L    I    T  F   T  S  O  F  T  T   N  E    H   T     F  C  T   U  W SQL   T 3 SQL  D Q L DQL  T U    D D L DDL  U   T V O  D C L DCL  M  D M L DML  U  U    SQL  O      D       C  P          C     L      R    L     U V     C    T SQL   SELECT  L  AND NOT OR  T   O  D      1 2  N    1 2  N  L  W  I  H  T  H    T   T  B   O  S       _ _  T   S ID  O  H    T    NULL  T NULL  I  L  I   A   W  N   S  T   S FN   W  T    I  S   W   S  A   O  S          N    L  S   W   S  A  L  W   L  W  L   I  T R E RE A RE  T  T RE     I  S  W  A  I  S J L J R J F J T    SID  N  P  E     1  J  1233454567     2  A  0000346758     3  M  3457684959     7  J  4859369485     CID  SID           1  N  D  I  J   2  A  F  S  B   3  J  L  N  D   4  M  P  A  D   5  S  B  A  F   6  M  S  L  C   7  R  K  J  L   8  L  C  R  K   9  A  D  M  P   10  I  J  M  S  T  S   C  T   T   D A SQL T  TODO  NOTE F   E   I   E D A EDA T   SQL  EDA SQL T SQL T   H  T SQL     T  F   SQL SQL SQL    F  C  I  T  O SQL   T  T   T D  T SQL  T          80 D T     W D T  T U SQL S T   S B  80 H MSQL U I     SQL S I B   R S   I    O__ O O  W              P C D E C O  4EED E D  PCDE N M 4 M   D D   L O SQL   R E RE  6 PCDE M 6 C B S D   E D A SQL   V D SQL   C D SQL   D  T SQL \n"
     ]
    }
   ],
   "source": [
    "# Markdown helper functions\n",
    "# Extract only prose elements of markdown text\n",
    "def extract_prose(text):\n",
    "    # Remove front matter\n",
    "    text = re.sub(r'---.*?---', '', text, flags=re.DOTALL)\n",
    "    # Remove italic bold\n",
    "    text = re.sub(r'\\*\\*\\*(.*?)\\*\\*\\*', r'\\1', text)\n",
    "    # Remove bold\n",
    "    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)\n",
    "    # Remove italic\n",
    "    text = re.sub(r'\\*(.*?)\\*', r'\\1', text)\n",
    "    # Remove code blocks including contents within them\n",
    "    text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)\n",
    "    # Remove inline code\n",
    "    text = re.sub(r'`.*?`', '', text)\n",
    "    # Remove the 2nd occurrence of square brackets for markdown reference links\n",
    "    # e.g. [link][1] -> [link]\n",
    "    text = re.sub(r'\\[(.*?)\\]\\[.*?\\]', r'[\\1]', text)\n",
    "    # Remove parenthesis and contents within them following square brackets of markdown links\n",
    "    # e.g. [link](https://www.google.com) -> [link]\n",
    "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    # Remove square brackets excluding contents within them\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    # Remove images\n",
    "    text = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    # Remove headings\n",
    "    text = re.sub(r'#+ .*', '', text)\n",
    "    # Remove horizontal rules\n",
    "    text = re.sub(r'---', '', text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove latex math\n",
    "    text = re.sub(r'\\$.*?\\$', '', text)\n",
    "    # Remove newlines\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Create a word counting dictionary from markdown text\n",
    "# e.g. the key is a word and the value is the number of times the word appears in the text\n",
    "def count_words(text):\n",
    "    text = extract_prose(text)\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    # Create a word counting dictionary using dict comprehension\n",
    "    word_counts = {w: words.count(w) for w in words}\n",
    "    return word_counts\n",
    "\n",
    "# Print words and their counts in order of descending counts\n",
    "def print_word_counts(word_counts):\n",
    "    # Sort word counts in descending order of counts\n",
    "    sorted_word_counts = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    # Print words and their counts\n",
    "    for word, count in sorted_word_counts:\n",
    "        print(f'{word}: {count}')\n",
    "\n",
    "def filter_out_common_words_from_text(text, common_words):\n",
    "    # Remove common words from text\n",
    "    for word in common_words:\n",
    "        print(f'Removing {word}')\n",
    "        text = text.replace(word, '')\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    # Remove punctuation and asterisks\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# sql_note_text = open(f'{NOTES_PATH}/sql.md').read()\n",
    "# extract_prose(sql_note_text)\n",
    "\n",
    "pronouns_set = ['i', 'me', 'my', 'mine', 'myself', 'we', 'us', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves']\n",
    "prepositions_set = ['aboard', 'about', 'above', 'across', 'after', 'against', 'along', 'amid', 'among', 'anti', 'around', 'as', 'at', 'before', 'behind', 'below', 'beneath', 'beside', 'besides', 'between', 'beyond', 'but', 'by', 'concerning', 'considering', 'despite', 'down', 'during', 'except', 'excepting', 'excluding', 'following', 'for', 'from', 'in', 'inside', 'into', 'like', 'minus', 'near', 'of', 'off', 'on', 'onto', 'opposite', 'outside', 'over', 'past', 'per', 'plus', 'regarding', 'round', 'save', 'since', 'than', 'through', 'to', 'toward', 'towards', 'under', 'underneath', 'unlike', 'until', 'up', 'upon', 'versus', 'via', 'with', 'within', 'without']\n",
    "alphabet_set = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "common_words = pronouns_set + prepositions_set + alphabet_set\n",
    "sql_note_text = open(f'{NOTES_PATH}/sql.md').read()\n",
    "sql_note_text = extract_prose(sql_note_text)\n",
    "sql_note_text = filter_out_common_words_from_text(sql_note_text, common_words)\n",
    "print(sql_note_text)\n",
    "# sql_word_counts = count_words(sql_note_text)\n",
    "# print_word_counts(sql_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
